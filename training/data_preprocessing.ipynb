{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "data_preprocessing.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "LibAOfhBBnR6",
        "colab_type": "code",
        "outputId": "9310f022-c0c6-4ba7-dc7e-fc84caf3abec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "\n",
        "%cd gdrive/My Drive/University/MAIS202/Final Project"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n",
            "/content/gdrive/My Drive/University/MAIS202/Final Project\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zr7Smd5GABnP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import re\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WyBpXpr7B9Sg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_word_len = 20"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMYuroRoFPMs",
        "colab_type": "code",
        "outputId": "4a972c51-6be8-4823-d17a-76cc6926478f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "path_data = 'data'\n",
        "\n",
        "path_cmu_dict = os.path.join(path_data, 'cmudict.txt')\n",
        "\n",
        "paths = {'src':{}, 'tgt':{}}\n",
        "\n",
        "for data_type in paths:\n",
        "    for set_type in ('train', 'val', 'test'):\n",
        "        paths[data_type][set_type] = os.path.join(path_data, '{}-{}.txt'.format(data_type, set_type))\n",
        "\n",
        "paths\n",
        "\n",
        "# path_src_train = os.path.join(path_data, 'src-train.txt')\n",
        "# path_tgt_train = os.path.join(path_data, 'tgt-train.txt')\n",
        "# path_src_val = os.path.join(path_data, 'src-val.txt')\n",
        "# path_tgt_val = os.path.join(path_data, 'tgt-val.txt')\n",
        "# path_src_test = os.path.join(path_data, 'src-test.txt')\n",
        "# path_tgt_test = os.path.join(path_data, 'tgt-test.txt')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'src': {'test': 'data/src-test.txt',\n",
              "  'train': 'data/src-train.txt',\n",
              "  'val': 'data/src-val.txt'},\n",
              " 'tgt': {'test': 'data/tgt-test.txt',\n",
              "  'train': 'data/tgt-train.txt',\n",
              "  'val': 'data/tgt-val.txt'}}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYuGNdo1Aknt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def is_valid(word):\n",
        "    return re.match('[A-Z]*$', word) and len(word) <= max_word_len\n",
        "\n",
        "def process(word):\n",
        "    # match = re.search('[A-Z]*', word)\n",
        "    # return match.group()\n",
        "    return word.replace(\"\", \" \")[1: -1]\n",
        "\n",
        "def remove_last(word):\n",
        "    return re.sub('(\\(\\d+\\))?$', '', word)\n",
        "\n",
        "def write_list_to_file(l, path_file):\n",
        "    with open(path_file, 'w') as file:\n",
        "        for item in l[:-1]:\n",
        "            file.write(item + '\\n')\n",
        "        file.write(l[-1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EarNpVa7_eeT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(path_cmu_dict, encoding='ISO-8859-1') as file_dict:\n",
        "    \n",
        "    # i = 0\n",
        "\n",
        "    clean_dict = {}\n",
        "    words_list = []\n",
        "    pronounciations_list = []\n",
        "\n",
        "    for line in file_dict:\n",
        "    \n",
        "        # skip comments\n",
        "        if line[:3] == ';;;':\n",
        "            continue\n",
        "        \n",
        "        # split line into word and pronounciation\n",
        "        word, pronounciation = line.strip().split('  ')\n",
        "        \n",
        "        # check if word is valid\n",
        "        if is_valid(word):\n",
        "            \n",
        "            # print('{}: {}'.format(word, pronounciation))\n",
        "\n",
        "            word_processed = process(word)\n",
        "\n",
        "            if word_processed not in clean_dict:\n",
        "                clean_dict[word_processed] = pronounciation\n",
        "                words_list.append(word_processed)\n",
        "                pronounciations_list.append(pronounciation)\n",
        "\n",
        "        #     i += 1\n",
        "        # if i == 5:\n",
        "        #     break\n",
        "\n",
        "# print(clean_dict)\n",
        "                    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHAyPHypFspB",
        "colab_type": "code",
        "outputId": "7c04aa5e-375f-4fde-9e36-7905f0e4af36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "print({k: clean_dict[k] for k in list(clean_dict)[:20]})\n",
        "print(words_list[:20])\n",
        "print(pronounciations_list[:20])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'A': 'AH0', 'A A': 'EY2 EY1', 'A A A': 'T R IH2 P AH0 L EY1', 'A A B E R G': 'AA1 B ER0 G', 'A A C H E N': 'AA1 K AH0 N', 'A A C H E N E R': 'AA1 K AH0 N ER0', 'A A H': 'AA1', 'A A K E R': 'AA1 K ER0', 'A A L I Y A H': 'AA2 L IY1 AA2', 'A A L S E T H': 'AA1 L S EH0 TH', 'A A M O D T': 'AA1 M AH0 T', 'A A N C O R': 'AA1 N K AO2 R', 'A A R D E M A': 'AA0 R D EH1 M AH0', 'A A R D V A R K': 'AA1 R D V AA2 R K', 'A A R D V A R K S': 'AA1 R D V AA2 R K S', 'A A R G H': 'AA1 R G', 'A A R O N': 'EH1 R AH0 N', 'A A R O N S': 'EH1 R AH0 N Z', 'A A R O N S O N': 'EH1 R AH0 N S AH0 N', 'A A R T I': 'AA1 R T IY2'}\n",
            "['A', 'A A', 'A A A', 'A A B E R G', 'A A C H E N', 'A A C H E N E R', 'A A H', 'A A K E R', 'A A L I Y A H', 'A A L S E T H', 'A A M O D T', 'A A N C O R', 'A A R D E M A', 'A A R D V A R K', 'A A R D V A R K S', 'A A R G H', 'A A R O N', 'A A R O N S', 'A A R O N S O N', 'A A R T I']\n",
            "['AH0', 'EY2 EY1', 'T R IH2 P AH0 L EY1', 'AA1 B ER0 G', 'AA1 K AH0 N', 'AA1 K AH0 N ER0', 'AA1', 'AA1 K ER0', 'AA2 L IY1 AA2', 'AA1 L S EH0 TH', 'AA1 M AH0 T', 'AA1 N K AO2 R', 'AA0 R D EH1 M AH0', 'AA1 R D V AA2 R K', 'AA1 R D V AA2 R K S', 'AA1 R G', 'EH1 R AH0 N', 'EH1 R AH0 N Z', 'EH1 R AH0 N S AH0 N', 'AA1 R T IY2']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHPg498EGW_C",
        "colab_type": "code",
        "outputId": "b15609f3-99b7-40b1-b09a-164b43e1ef0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "words = {}\n",
        "pronounciations = {}\n",
        "\n",
        "words['train'], words['test'], pronounciations['train'], pronounciations['test'] = train_test_split(\n",
        "    words_list, pronounciations_list, test_size=0.2, random_state=3791)\n",
        "\n",
        "words['train'], words['val'], pronounciations['train'], pronounciations['val'] = train_test_split(\n",
        "    words['train'], pronounciations['train'], test_size=0.125, random_state=3791)\n",
        "\n",
        "print(len(words['train']), len(words['test']), len(words['val']), len(\n",
        "    pronounciations['train']), len(pronounciations['test']), len(pronounciations['val']))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "81551 23301 11651 81551 23301 11651\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sc20tks2IhZP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for set_type in ('train', 'test', 'val'):\n",
        "    write_list_to_file(words[set_type], paths['src'][set_type])\n",
        "    write_list_to_file(pronounciations[set_type], paths['tgt'][set_type])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_GKWDoWSr6O",
        "colab_type": "code",
        "outputId": "d2cb7343-c1ce-4f82-9e61-c98e986a2084",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "chars = set()\n",
        "phonemes = set()\n",
        "\n",
        "for word in words_list:\n",
        "    for char in word.split():\n",
        "        chars.add(char)\n",
        "\n",
        "for pronounciation in pronounciations_list:\n",
        "    for phoneme in pronounciation.split():\n",
        "        phonemes.add(phoneme)\n",
        "\n",
        "print(len(chars))\n",
        "print(chars)\n",
        "\n",
        "print(len(phonemes))\n",
        "print(phonemes)\n",
        "\n",
        "write_list_to_file(list(chars), os.path.join(path_data, 'src-vocab.txt'))\n",
        "write_list_to_file(list(phonemes), os.path.join(path_data, 'tgt-vocab.txt'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "26\n",
            "{'P', 'F', 'R', 'D', 'Z', 'E', 'C', 'J', 'X', 'N', 'O', 'A', 'B', 'I', 'Q', 'W', 'Y', 'V', 'K', 'L', 'S', 'H', 'T', 'M', 'U', 'G'}\n",
            "69\n",
            "{'SH', 'AY1', 'IY0', 'OW0', 'EH1', 'IH1', 'P', 'AW0', 'IH2', 'OW2', 'IH0', 'F', 'R', 'D', 'ER0', 'AH2', 'ER2', 'Z', 'OW1', 'UH1', 'AW1', 'EY2', 'OY2', 'N', 'EY0', 'AY2', 'EH0', 'B', 'AE0', 'UW0', 'EH2', 'AE1', 'UW2', 'UW1', 'AO0', 'W', 'IY2', 'Y', 'AO1', 'AY0', 'AW2', 'CH', 'V', 'UH2', 'HH', 'UH0', 'AH1', 'IY1', 'AE2', 'JH', 'ZH', 'ER1', 'K', 'AH0', 'L', 'OY0', 'AO2', 'S', 'DH', 'EY1', 'AA0', 'OY1', 'TH', 'AA1', 'NG', 'T', 'AA2', 'M', 'G'}\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}